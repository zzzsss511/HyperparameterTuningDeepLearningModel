{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load related library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = pd.read_csv(\"./Data/train.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainSet.drop(columns=['Name', 'PassengerId', 'Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   Survived  100000 non-null  int64  \n",
      " 1   Pclass    100000 non-null  int64  \n",
      " 2   Sex       100000 non-null  object \n",
      " 3   Age       96708 non-null   float64\n",
      " 4   SibSp     100000 non-null  int64  \n",
      " 5   Parch     100000 non-null  int64  \n",
      " 6   Fare      99866 non-null   float64\n",
      " 7   Embarked  99750 non-null   object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96332 entries, 2 to 99999\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  96332 non-null  int64  \n",
      " 1   Pclass    96332 non-null  int64  \n",
      " 2   Sex       96332 non-null  object \n",
      " 3   Age       96332 non-null  float64\n",
      " 4   SibSp     96332 non-null  int64  \n",
      " 5   Parch     96332 non-null  int64  \n",
      " 6   Fare      96332 non-null  float64\n",
      " 7   Embarked  96332 non-null  object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy coding of the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, validation data set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train.drop(columns=\"Survived\", axis=0)\n",
    "                                                , train['Survived']\n",
    "                                                , test_size=0.2\n",
    "                                                , random_state=2023\n",
    "                                                , stratify=train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def nn_cl_bo(neurons, activation, optimizer, learning_rate,  batch_size, epochs ):\n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    neurons = round(neurons)\n",
    "    activation = activationL[round(activation)]\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    def nn_cl_fun():\n",
    "        opt = Adam(lr = learning_rate)\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(neurons, input_dim=10, activation=activation))\n",
    "        nn.add(Dense(neurons, activation=activation))\n",
    "        nn.add(Dense(1, activation='sigmoid'))\n",
    "        nn.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return nn\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
    "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size,\n",
    "                         verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_nn = {\n",
    "    'neurons': (10, 100)\n",
    "  , 'activation': (0, 9) # `activationL` has 10 elements\n",
    "  , 'optimizer': (0, 7) # `optimizerL` has 8 elements\n",
    "  , 'learning_rate': (0.01, 1)\n",
    "  , 'batch_size': (200, 1000)\n",
    "  , \"epochs\": (20, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  epochs   | learni... |  neurons  | optimizer |\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 23:19:24.556171: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.7602   \u001b[0m | \u001b[0m2.898    \u001b[0m | \u001b[0m912.3    \u001b[0m | \u001b[0m67.04    \u001b[0m | \u001b[0m0.1353   \u001b[0m | \u001b[0m22.72    \u001b[0m | \u001b[0m3.275    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m0.1988   \u001b[0m | \u001b[0m781.8    \u001b[0m | \u001b[0m61.95    \u001b[0m | \u001b[0m0.5495   \u001b[0m | \u001b[0m51.07    \u001b[0m | \u001b[0m3.51     \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.5431   \u001b[0m | \u001b[0m3.55     \u001b[0m | \u001b[0m320.9    \u001b[0m | \u001b[0m48.87    \u001b[0m | \u001b[0m0.1705   \u001b[0m | \u001b[0m40.42    \u001b[0m | \u001b[0m1.262    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.4856   \u001b[0m | \u001b[0m3.519    \u001b[0m | \u001b[0m228.5    \u001b[0m | \u001b[0m65.19    \u001b[0m | \u001b[0m0.2114   \u001b[0m | \u001b[0m38.85    \u001b[0m | \u001b[0m2.636    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m1.656    \u001b[0m | \u001b[0m283.2    \u001b[0m | \u001b[0m56.39    \u001b[0m | \u001b[0m0.2039   \u001b[0m | \u001b[0m44.07    \u001b[0m | \u001b[0m6.514    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m6.841    \u001b[0m | \u001b[0m816.6    \u001b[0m | \u001b[0m67.74    \u001b[0m | \u001b[0m0.7937   \u001b[0m | \u001b[0m82.93    \u001b[0m | \u001b[0m6.864    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.6995   \u001b[0m | \u001b[0m7.963    \u001b[0m | \u001b[0m287.8    \u001b[0m | \u001b[0m85.58    \u001b[0m | \u001b[0m0.3145   \u001b[0m | \u001b[0m33.53    \u001b[0m | \u001b[0m2.84     \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.5144   \u001b[0m | \u001b[0m4.981    \u001b[0m | \u001b[0m700.4    \u001b[0m | \u001b[0m26.3     \u001b[0m | \u001b[0m0.9726   \u001b[0m | \u001b[0m47.02    \u001b[0m | \u001b[0m5.052    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.4856   \u001b[0m | \u001b[0m5.97     \u001b[0m | \u001b[0m374.6    \u001b[0m | \u001b[0m34.97    \u001b[0m | \u001b[0m0.7325   \u001b[0m | \u001b[0m87.7     \u001b[0m | \u001b[0m2.742    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m0.9904   \u001b[0m | \u001b[0m930.2    \u001b[0m | \u001b[0m48.56    \u001b[0m | \u001b[0m0.4188   \u001b[0m | \u001b[0m26.52    \u001b[0m | \u001b[0m4.102    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6551   \u001b[0m | \u001b[0m7.701    \u001b[0m | \u001b[0m831.7    \u001b[0m | \u001b[0m27.03    \u001b[0m | \u001b[0m0.9337   \u001b[0m | \u001b[0m55.0     \u001b[0m | \u001b[0m2.55     \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.5144   \u001b[0m | \u001b[0m4.352    \u001b[0m | \u001b[0m612.2    \u001b[0m | \u001b[0m99.57    \u001b[0m | \u001b[0m0.7559   \u001b[0m | \u001b[0m42.92    \u001b[0m | \u001b[0m4.28     \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.5144   \u001b[0m | \u001b[0m3.777    \u001b[0m | \u001b[0m273.3    \u001b[0m | \u001b[0m62.79    \u001b[0m | \u001b[0m0.3474   \u001b[0m | \u001b[0m11.65    \u001b[0m | \u001b[0m4.224    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6757   \u001b[0m | \u001b[0m8.296    \u001b[0m | \u001b[0m425.1    \u001b[0m | \u001b[0m86.78    \u001b[0m | \u001b[0m0.5541   \u001b[0m | \u001b[0m11.96    \u001b[0m | \u001b[0m2.429    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.5931   \u001b[0m | \u001b[0m4.95     \u001b[0m | \u001b[0m210.6    \u001b[0m | \u001b[0m77.27    \u001b[0m | \u001b[0m0.1979   \u001b[0m | \u001b[0m76.82    \u001b[0m | \u001b[0m4.406    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.5144   \u001b[0m | \u001b[0m3.26     \u001b[0m | \u001b[0m701.6    \u001b[0m | \u001b[0m61.19    \u001b[0m | \u001b[0m0.896    \u001b[0m | \u001b[0m56.68    \u001b[0m | \u001b[0m4.252    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.4856   \u001b[0m | \u001b[0m4.273    \u001b[0m | \u001b[0m767.7    \u001b[0m | \u001b[0m29.22    \u001b[0m | \u001b[0m0.7355   \u001b[0m | \u001b[0m89.02    \u001b[0m | \u001b[0m3.633    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.6279   \u001b[0m | \u001b[0m6.124    \u001b[0m | \u001b[0m548.4    \u001b[0m | \u001b[0m97.74    \u001b[0m | \u001b[0m0.3715   \u001b[0m | \u001b[0m66.04    \u001b[0m | \u001b[0m1.808    \u001b[0m |\n",
      "| \u001b[95m19       \u001b[0m | \u001b[95m0.7665   \u001b[0m | \u001b[95m6.132    \u001b[0m | \u001b[95m901.3    \u001b[0m | \u001b[95m39.38    \u001b[0m | \u001b[95m0.1512   \u001b[0m | \u001b[95m84.29    \u001b[0m | \u001b[95m3.258    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.6147   \u001b[0m | \u001b[0m3.044    \u001b[0m | \u001b[0m946.9    \u001b[0m | \u001b[0m56.35    \u001b[0m | \u001b[0m0.4993   \u001b[0m | \u001b[0m14.13    \u001b[0m | \u001b[0m0.8328   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.5432   \u001b[0m | \u001b[0m4.842    \u001b[0m | \u001b[0m243.8    \u001b[0m | \u001b[0m44.04    \u001b[0m | \u001b[0m0.3843   \u001b[0m | \u001b[0m64.81    \u001b[0m | \u001b[0m5.767    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m1.646    \u001b[0m | \u001b[0m829.5    \u001b[0m | \u001b[0m44.91    \u001b[0m | \u001b[0m0.7738   \u001b[0m | \u001b[0m92.35    \u001b[0m | \u001b[0m1.584    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m8.92     \u001b[0m | \u001b[0m449.2    \u001b[0m | \u001b[0m90.85    \u001b[0m | \u001b[0m0.6967   \u001b[0m | \u001b[0m14.91    \u001b[0m | \u001b[0m1.413    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.7027   \u001b[0m | \u001b[0m7.732    \u001b[0m | \u001b[0m728.6    \u001b[0m | \u001b[0m89.82    \u001b[0m | \u001b[0m0.7265   \u001b[0m | \u001b[0m18.27    \u001b[0m | \u001b[0m0.1538   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.6082   \u001b[0m | \u001b[0m1.638    \u001b[0m | \u001b[0m420.9    \u001b[0m | \u001b[0m73.87    \u001b[0m | \u001b[0m0.5748   \u001b[0m | \u001b[0m43.96    \u001b[0m | \u001b[0m1.992    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m8.967    \u001b[0m | \u001b[0m286.7    \u001b[0m | \u001b[0m82.98    \u001b[0m | \u001b[0m0.822    \u001b[0m | \u001b[0m31.15    \u001b[0m | \u001b[0m1.788    \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.6333   \u001b[0m | \u001b[0m0.7243   \u001b[0m | \u001b[0m633.6    \u001b[0m | \u001b[0m81.66    \u001b[0m | \u001b[0m0.1544   \u001b[0m | \u001b[0m78.6     \u001b[0m | \u001b[0m4.486    \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.7399   \u001b[0m | \u001b[0m7.526    \u001b[0m | \u001b[0m223.9    \u001b[0m | \u001b[0m29.33    \u001b[0m | \u001b[0m0.09653  \u001b[0m | \u001b[0m50.95    \u001b[0m | \u001b[0m2.094    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.5719   \u001b[0m | \u001b[0m0.607    \u001b[0m | \u001b[0m888.6    \u001b[0m | \u001b[0m68.44    \u001b[0m | \u001b[0m0.5056   \u001b[0m | \u001b[0m21.14    \u001b[0m | \u001b[0m5.445    \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=2023)\n",
    "nn_bo.maximize(init_points=25, n_iter=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'elu',\n",
       " 'batch_size': 901.2735443367724,\n",
       " 'epochs': 39.38147955457231,\n",
       " 'learning_rate': 0.1512058724048746,\n",
       " 'neurons': 84.28502005730954,\n",
       " 'optimizer': 'Adadelta'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_nn_ = nn_bo.max['params']\n",
    "\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential', LeakyReLU,'relu']\n",
    "params_nn_['activation'] = activationL[round(params_nn_['activation'])]\n",
    "\n",
    "optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "params_nn_['optimizer'] = optimizerL[round(params_nn_['optimizer'])]\n",
    "params_nn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6e4d5ef8480bde448feb7aa7993cda4fb0b67d180e6017422e62b472b016cda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
